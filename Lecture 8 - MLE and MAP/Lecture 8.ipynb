{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8 - Maximum Likelihood and Maximum A Posteriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the **Regularized Least Squares** in the \"Objective Function world\", where we simply add a term to our objective in order to prevent overfitting and, consequently, allow the model to generalize to unseen and unkown data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Interpretation\n",
    "\n",
    "Another way to look at Regularized Least Squares is from a Bayesian point-of-view. To see this, let's look at our objective function:\n",
    "\n",
    "\\begin{align}\n",
    "& \\arg_{\\mathbf{w}}\\min \\left(J(\\mathbf{w})\\right) \\\\\n",
    "= & \\arg_{\\mathbf{w}}\\max \\left(- J(\\mathbf{w})\\right) \\\\\n",
    "= & \\arg_{\\mathbf{w}}\\max \\left(\\exp\\left(- J(\\mathbf{w})\\right)\\right) \\text{, }\\exp(\\bullet)\\text{ is a monotonic function}  \n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\n",
    "$$J(\\mathbf{w})= \\frac{1}{2}\\sum_{n=1}^N \\left(t_n - y_n\\right)^2 - \\frac{\\lambda}{2} \\sum_{i=0}^M w_i^2$$\n",
    "and, consider e.g. the polynomial model (this could be *any* model)\n",
    "$$y_n = \\sum_{j=0}^M w_jx_n^j$$\n",
    "\n",
    "Then,\n",
    "\n",
    "\\begin{align}\n",
    "& \\arg_{\\mathbf{w}}\\max \\left(\\exp\\left(-\\frac{1}{2}\\sum_{n=1}^N \\left(t_n - y_n\\right)^2 - \\frac{\\lambda}{2} \\sum_{i=0}^M w_i^2)\\right)\\right) \\\\\n",
    "= & \\arg_{\\mathbf{w}}\\max \\left(\\exp\\left(-\\frac{1}{2}\\sum_{n=1}^N \\left(t_n - y_n\\right)^2\\right) \\exp\\left(- \\frac{\\lambda}{2} \\sum_{i=0}^M w_i^2)\\right)\\right) \\\\\n",
    "=& \\arg_{\\mathbf{w}}\\max \\left(\\prod_{n=1}^N \\exp\\left(-\\frac{1}{2}\\left(t_n - y_n\\right)^2\\right) \\prod_{i=0}^M \\exp \\left(-\\frac{\\lambda}{2} w_i^2\\right) \\right)\\text{, assuming the data }\\{(x_n,t_n)\\}_{n=1}^N\\text{ is i.i.d.}  \\\\\n",
    "\\approx & \\arg_{\\mathbf{w}}\\max \\mathcal{N}\\left(\\mathbf{t}| \\mathbf{y}, 1\\right) \\mathcal{N}\\left(0, 1/\\lambda\\right) \\\\\n",
    "=& \\arg_{\\mathbf{w}}\\max p(\\mathbf{t}|\\mathbf{w}) p(\\mathbf{w}), \\mathbf{y}\\text{ is a function of }\\mathbf{w}\\\\\n",
    "=& \\arg_{\\mathbf{w}}\\max p(\\mathbf{w}|\\mathbf{t}) p(\\mathbf{t}), \\text{ using Bayes' Rule} \\\\\n",
    "\\propto & \\arg_{\\mathbf{w}}\\max p(\\mathbf{w}|\\mathbf{t}), p(\\mathbf{t})\\text{ is constant for some fixed training set}  \n",
    "\\end{align}\n",
    "\n",
    "where $p(\\mathbf{t}|\\mathbf{w})$ is known as the **data likelihood**, $p(\\mathbf{w})$ is known as the **prior** on the parameters, and $p(\\mathbf{w}|\\mathbf{t})$ is the **posterior probability**.\n",
    "\n",
    "In Machine Learning, this result is known as the **evidence approximation**.\n",
    "\n",
    "* In practice, this means that we now can rewrite the Regularized Least Squares problem as the product between the *data likelihood* and a *prior distribution* on the parameters. \n",
    "\n",
    "    * In particular, for Least Squares cost function and an L2- regularization term, both distributions (likelihood's and prior's) follow a Gaussian distribution.\n",
    "    \n",
    "* Now, we can select **any** distribution function to our data and control the regularization also using a probabilistic model!\n",
    "\n",
    "* **What is the shape of the prior distribution if we had considered the L1-norm or the Lasso regularizer?**\n",
    "\n",
    "* **Using the same manipulation, what our optimization function look like *without* a regularization term?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-4,4,1000)\n",
    "Gaussian = np.exp(-x**2/2)/np.sqrt(2*np.pi) #Gaussian with zero-mean and unit-variance\n",
    "Laplacian = np.exp(-np.abs(x))/(2) #Laplacian with zero-mean and lambda=1\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(x, Gaussian, label='Gaussian Distribution')\n",
    "plt.plot(x, Laplacian, label='Laplacian Distribution')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"p(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another note on Feature Selection\n",
    "\n",
    "And, again, the L1-norm penalty (or *Lasso regularizer*) term *prefers* to have the weight parameters to be zero whereas the squared L2-norm penalty (or *ridge regularizer*) term *prefers* to have non-zero elements in $\\mathbf{w}$.\n",
    "\n",
    "The Lasso regularizer promotes sparsity, which can be used to perform feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation (MLE) & Maximum A Posteriori (MAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our goal is to find the set of (hyper-)parameters that best fit our data. \n",
    "\n",
    "For the **Regularized Least Squares** objective function, we just showed that our optimization problem can be reduced to:\n",
    "\n",
    "* Maximizing the **posterior** probability, that takes the shape of a Gaussian distribution, of unknown (hyper-)parameters, also known as **hypothesis** in the statistical inferencing.\n",
    "\n",
    "For the **Least Squares without regularization** objective function, we just showed that our optimization problem can be reduced to:\n",
    "\n",
    "* Maximizing the **data likelihood**, that takes the shape of a Gaussian distribution, with unknown (hyper-)parameters, also known as **hypothesis** in the statistical inferencing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the decision rules for statistical inferencing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "  <strong>Maximum Likelihood (ML) Decision Rule</strong>\n",
    "\n",
    "Given some observational data $\\{x_i,t_i\\}_{i=1}^N$, we can perform *classical* (or frequentist) statistical inferencing by computing the probability of 2 hypothesis, $H_0$ and $H_1$. The decision rule is given by:\n",
    "    \n",
    "$$P(\\text{data}|H_0) \\underset{H_1}{\\overset{H_0}{\\gtrless}} P(\\text{data}|H_1)$$\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "  <strong>Maximum A Posteriori (MAP) Decision Rule</strong>\n",
    "\n",
    "Given some observational data $\\{x_i,t_i\\}_{i=1}^N$, we can perform Bayesian statistical inferencing by testing different hypothesis $\\{H_i\\}, i=1,2,3,4, \\dots$, each with an induced **prior** probability $P(H_i)\\neq 0, \\forall i$. The decision rule is given by:\n",
    "\n",
    "\\begin{align}\n",
    "P(H_i|\\text{data}) &\\underset{H_j}{\\overset{H_i}{\\gtrless}} P(H_j|\\text{data}), i\\neq j \\\\\n",
    "\\iff \\frac{P(\\text{data}|H_i)P(H_i)}{P(\\text{data})} &\\underset{H_j}{\\overset{H_i}{\\gtrless}} \\frac{P(\\text{data}|H_j)P(H_j)}{P(\\text{data})}\\\\\n",
    "\\iff P(\\text{data}|H_i)P(H_i) &\\underset{H_j}{\\overset{H_i}{\\gtrless}} P(\\text{data}|H_j)P(H_j), P(\\text{data})\\neq 0\n",
    "\\end{align}\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our problem, the hypothesis are the *unknown* **(hyper-)parameters** $\\mathbf{w}$.\n",
    "\n",
    "* In Bayesian statistical inferencing, we are then trying to find the $\\mathbf{w}$'s that maximizing the posterior probability.\n",
    "* In classical statistical inferencing, on the other hand, we are only computing the probability of some hypothesis (the *null hypothesis*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:blue\">Maximum Likelihood Estimation (MLE)</span></h2>\n",
    "<center>(Frequentist approach)</center>\n",
    "\n",
    "In **Maximum Likelihood Estimation** (also referred to as **MLE** or **ML**) we want to *find the set of parameters* that **maximize** the data likelihood $P(\\mathbf{x}|\\mathbf{w})$. We want to find the *optimal* set of parameters under some assumed distribution such that the data is most likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:orange\">Maximum A Posteriori (MAP)</span></h2>\n",
    "<center>(Bayesian approach)</center>\n",
    "\n",
    "In **Maximum A Posteriori** (also referred as **MAP**) we want to *find the set of parameters* that **maximize** the posteriori probability $P(\\mathbf{w}|\\mathbf{x})$. We want to find the *optimal* set of parameters under some assumed distribution such that the parameters are most likely to have been drawn off of given some prior beliefs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "**Problem: Suppose I flip a coin 3 times and observe the event H-H-H. What is the probability of flipping Heads (H) on the next coin flip?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $H_i$ be the event that it comes up heads on flip $i$. The sample space for this experiment is $S=\\{H,T\\}$. Consider the event $E=H_1\\cap H_2\\cap H_3$.\n",
    "\n",
    "1. From Classical probability, what is the probability of heads in the next flip?\n",
    "\n",
    "    * $P(H) = \\frac{|H|}{|S|} = \\frac{3}{3} = 1$\n",
    "\n",
    "2. Bayesian Inference: What is the **hidden state** in this problem?\n",
    "\n",
    "    * Hidden state: what type of coin was use in the experiment (fair, 2-headed)\n",
    "    * So, by Law of Total Probability:\n",
    "    $P(H) = P(H|\\text{fair})P(\\text{fair}) + P(\\overline{H}|\\text{2-headed})P(\\text{2-headed})$\n",
    "    * Furthermore, we can test different hypothesis by checking which hypothesis has the largest posterior probability value, e.g. if $P(\\text{fair}|E) > P(\\text{2-headed}|E)$, then hypothesis \"fair\" is more likely and that is what we will use to make predictions.\n",
    "    \n",
    "    \n",
    "3. Note that the outcomes $H_i$ are **conditionally independent**, that is: $P(H_1\\cap H_2|\\text{fair}) = P(H_1|\\text{fair})P(H_2|\\text{fair})$. \n",
    "    * This is often an assumption that we make about data samples, we say that the samples are **independent and identically distributed (i.i.d.)**.\n",
    "    \n",
    "4. Recall that an experiment is **fair** if and only if (iff) the probability of each possible outcome (H,T) is equally likely to happen.\n",
    "\n",
    "    * E.g., if $P(H)=P(T)=\\frac{1}{2}$ then the experiment is fair.\n",
    "    * But in this problem we do not know the probability of the outcomes are. In fact, that is exactly what we seek. Just like the polynomial regression problem, where we are finding the best hypothesis model but do not know which parameter values $\\mathbf{w}$ to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's consider heads=1 and tails=0, so our sample space is $S=\\{1,0\\}$. The probability of heads is equal to some *unknown* value $\\mu$, then:\n",
    "\n",
    "\\begin{align}\n",
    "& P(x=1 | \\mu) = \\mu \\\\\n",
    "& P(x=0|\\mu) = 1-\\mu\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the data likelihood as:\n",
    "\n",
    "$$P(x|\\mu) = \\mu^x(1-\\mu)^{1-x} = \\begin{cases}\\mu & \\text{if }x=1 \\\\ 1-\\mu & \\text{if } x=0 \\end{cases}$$\n",
    "\n",
    "* This is the **Bernoulli distribution**. The mean and variance of the Bernoulli distribution are: $E[x] = \\mu$ and $E[\\left(x- E[x]\\right)^2] = \\mu(1-\\mu)$.\n",
    "\n",
    "* So, for every outcome of the event $E$, we will model it using a Bernoulli distribution, and each outcome is pairwise **conditionally independent**. Therefore, we have the event $E$ contains i.i.d. outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Maximum Likelihood Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity of calculation, assume that the event contains outcomes: $E=x_1\\cap x_2\\cap \\dots\\cap x_N$, where $x_i=\\{0,1\\}$ (0 for Tails and 1 for Heads). Then, for an experiment with $N$ samples, we can write the **data likelihood** as:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "P(E|\\mu) &= P(x_1\\cap x_2\\cap \\dots\\cap x_N|\\mu) \\\\\n",
    "&= P(x_1|\\mu)P(x_2|\\mu)\\dots P(x_N|\\mu) \\\\\n",
    "&= \\prod_{n=1}^N P(x_n|\\mu) \\\\\n",
    "&= \\prod_{n=1}^N \\mu^{x_n} (1-\\mu)^{1-x_n}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we are interested in finding the value of $\\mu$ given some data set $E$. \n",
    "\n",
    "We now optimize the data likelihood. What trick can we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$arg_\\mathbf{\\mu} \\max P(E|\\mu) = \\arg_\\mathbf{\\mu} \\max \\ln \\left( P(E|\\mu) \\right)$$\n",
    "\n",
    "because the $\\ln(\\bullet)$ is a monotonic function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where \n",
    "$$\\ln(P(E|\\mu) = \\sum_{n=1}^N \\left(x_n \\ln(\\mu) + (1-x_n)\\ln(1-\\mu)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can take the derivative of this function wrt to $\\mu$ and equal it to zero:\n",
    "\n",
    "$$\\frac{\\partial \\ln(P(E|\\mu))}{\\partial \\mu} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "(1-\\mu)\\sum_{n=1}^N x_n - \\mu \\left(N - \\sum_{n=1}^N x_n\\right) &= 0 \\\\\n",
    "\\sum_{n=1}^N x_n - \\mu\\sum_{n=1}^N x_n - \\mu N + \\mu\\sum_{n=1}^N x_n &= 0 \\\\\n",
    "\\sum_{n=1}^N x_n - \\mu N &= 0 \\\\\n",
    "\\mu &= \\frac{1}{N} \\sum_{n=1}^N x_n\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the MLE estimation of the probability of seeing heads in the next coin flip is equal to **relative frequency** of outcome heads.\n",
    "\n",
    "* Suppose you flipped the coin only once, and saw Tails. The probability of flipping Heads according to MLE would be 0.\n",
    "\n",
    "* MLE is **purely data driven**! This is sufficient *when* we have lots and lots of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Maximum A Posteriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the MAP estimation of $\\mu$, we are instead optimizing the posterior probability:\n",
    "\n",
    "\\begin{align}\n",
    "&\\arg_{\\mu} \\max P(\\mu|E) \\\\\n",
    "=& \\arg_{\\mu} \\max \\frac{P(E|\\mu) P(\\mu)}{P(E)} \\\\\n",
    "\\propto & \\text{  } \\arg_{\\mu} \\max P(E|\\mu) P(\\mu), P(E)\\text{ is some constant value} \n",
    "\\end{align}\n",
    "\n",
    "We have defined the data likelihood $P(E|\\mu)$, we now need to choose a **prior distribution** $P(\\mu)$.\n",
    "\n",
    "* This prior distribution will *encode* any prior knowledge we have about the hidden sate of the problem, in this case, the type of coin that was used.\n",
    "\n",
    "Let's say our **prior distribution** is a Beta Distribution. A **Beta Distribution** takes the form:\n",
    "\n",
    "$$\\text{Beta}(x|\\alpha,\\beta) = \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1}$$\n",
    "\n",
    "where $\\Gamma(x) = (x-1)!$ and $\\alpha,\\beta>0$.\n",
    "\n",
    "The mean and variance of the Beta distribution are: $E[x] = \\frac{\\alpha}{\\alpha+\\beta}$ and $E[(x-E[x])^2] = \\frac{\\alpha\\beta}{(\\alpha+\\beta)^2(\\alpha+\\beta+1)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's see what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "a = 2\n",
    "b = 2\n",
    "x = np.arange(0,1,0.0001)\n",
    "Beta = (math.gamma(a+b)/(math.gamma(a)*math.gamma(b)))*x**(a-1)*(1-x)**(b-1)\n",
    "\n",
    "plt.plot(x, Beta, label='Beta Distribution')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Probability of Heads, $\\mu$',fontsize=15)\n",
    "plt.ylabel('Prior Probability, p($\\mu$)',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Beat Distribution as out prior, we have:\n",
    "\n",
    "\\begin{align}\n",
    "P(\\mu|\\alpha,\\beta) &= \\frac{\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&\\propto \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let:\n",
    "* $m$ the number of heads\n",
    "* $l$ the number of tails\n",
    "* $N=m+l$ the total number of coin flips \n",
    "\n",
    "We can write our **posterior probability** as:\n",
    "\n",
    "\\begin{align}\n",
    "P(\\mu|E) &= \\frac{P(E|\\mu)P(\\mu)}{P(E)}\\\\\n",
    "&\\propto P(E|\\mu)P(\\mu)\\\\\n",
    "&= \\left(\\prod_{n=1}^N \\mu^{x_n} (1-\\mu)^{1-x_n}\\right) \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&= \\mu^m (1-\\mu)^l \\mu^{\\alpha-1} (1-\\mu)^{\\beta-1} \\\\\n",
    "&= \\mu^{m+\\alpha-1} (1-\\mu)^{l+\\beta-1}\n",
    "\\end{align}\n",
    "\n",
    "* The posterior probability has the same shape as the data likelihood. \n",
    "\n",
    "* This is a special case called **Conjugate Prior Relationship**, which happens when the posterior has the same form as the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now optimize our posterior probability, and we will apply the same trick:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$arg_\\mathbf{\\mu} \\max P(\\mu|E) = \\arg_\\mathbf{\\mu} \\max \\ln \\left( P(\\mu|E) \\right)$$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\ln \\left( P(\\mu|E) \\right) =  (m+\\alpha-1)\\ln(\\mu) + (l+\\beta-1)\\ln(1-\\mu)$$\n",
    "\n",
    "We can now *optimize* our posterior probability:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial  \\ln \\left( P(\\mu|E) \\right)}{\\partial \\mu} &= 0\\\\\n",
    "\\frac{m+\\alpha-1}{\\mu} + \\frac{l+\\beta-1}{1-\\mu} &= 0\\\\\n",
    "\\mu &= \\frac{m+\\alpha-1}{m + l + \\alpha + \\beta -2}\n",
    "\\end{align}\n",
    "\n",
    "This is our estimation of the probability of heads using MAP!\n",
    "\n",
    "* Our estimation for the probability of heads, $\\mu$, is going to depend on $\\alpha$ and $\\beta$ introduced by the prior distribution. We saw that they control the level of certainty as well as the center value.\n",
    "\n",
    "* With only a few samples, the prior will play a bigger role in the decision, but eventually the data takes over the prior.\n",
    "\n",
    "Let's run a simulation to compare MAP and MLE estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueMU = 0.5 # 0.5 for a fair coin\n",
    "Nflips = 10\n",
    "a = 2\n",
    "b = 10\n",
    "\n",
    "Outcomes = []\n",
    "for i in range(Nflips):\n",
    "    Outcomes += [stats.bernoulli(trueMU).rvs(1)[0]]\n",
    "    print(Outcomes)\n",
    "    print('MLE aka Frequentist Probability of Heads = ', np.sum(Outcomes)/len(Outcomes))\n",
    "    print('MAP aka Bayesian Probability of Heads = ', (np.sum(Outcomes)+a-1)/(len(Outcomes)+a+b-2))\n",
    "    input('Press enter to flip the coin again...\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:blue\">Maximum Likelihood Estimation (MLE)</span></h2>\n",
    "<center>(Frequentist approach)</center>\n",
    "\n",
    "$$\\arg_{\\mathbf{w}} \\max P(\\mathbf{x}|\\mathbf{w})$$\n",
    "\n",
    "In **Maximum Likelihood Estimation** we *find the set of parameters* that **maximize** the data likelihood $P(\\mathbf{x}|\\mathbf{w})$. We find the *optimal* set of parameters under some assumed distribution such that the data is most likely.\n",
    "\n",
    "* MLE focuses on maximizing the data likelihood, which *usually* provides a pretty good estimate\n",
    "\n",
    "* A common trick to maximize the data likelihood is to maximize the log likelihood\n",
    "\n",
    "* MLE is purely data driven \n",
    "\n",
    "* MLE works best when we have lots and lots of data\n",
    "\n",
    "* MLE will likely overfit when we have small amounts of data or, at least, becomes unreliable\n",
    "\n",
    "* It estimates relative frequency for our model parameters. Therefore it needs incredibly large amounts of data (infinite!) to estimate the true likelihood parameters\n",
    "    * This is a problem when we want to make inferences and/or predictions outside the range of what the training data has learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "<h2 align=\"center\"><span style=\"color:orange\">Maximum A Posteriori (MAP)</span></h2>\n",
    "<center>(Bayesian approach)</center>\n",
    "\n",
    "\\begin{align}\n",
    "& \\arg_{\\mathbf{w}} \\max P(\\mathbf{x}|\\mathbf{w})P(\\mathbf{w}) \\\\ \n",
    "& \\propto \\arg_{\\mathbf{w}} \\max P(\\mathbf{w}|\\mathbf{x})\n",
    "\\end{align}\n",
    "\n",
    "In **Maximum A Posteriori** we *find the set of parameters* that **maximize** the the posterior probability $P(\\mathbf{w}|\\mathbf{x})$. We find the *optimal* set of parameters under some assumed distribution such that the parameters are most likely to have been drawn off of.\n",
    "\n",
    "* MAP focuses on maximizing the posterior probability - data  likelihood with a prior\n",
    "\n",
    "* A common trick to maximize the posterior probability is to maximize the log likelihood\n",
    "\n",
    "* MAP is data driven \n",
    "\n",
    "* MAP is mostly driven by the prior beliefs\n",
    "\n",
    "* MAP works great with small amounts of data *if* our prior was chosen well\n",
    "\n",
    "* We need to assume and select a distribution for our prior beliefs\n",
    "    * A wrong choice of prior distribution can impact negatively our model estimation\n",
    "    \n",
    "* When we have lots and lots of data, the data likelihood will take over and the posterior will depend less and less on the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
